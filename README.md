# ğŸ§  Private AI Research & Retrieval Stack

A modular, self-hosted AI stack for intelligent document retrieval, natural language processing, code generation, and live research â€” entirely on your own hardware.

---

## ğŸ—ï¸ Project Overview

This stack is designed to provide an alternative to hosted AI services like ChatGPT, with full local control over your data, documents, and model choices. It supports:

- **Retrieval-Augmented Generation (RAG)**: Ask questions and get answers grounded in your private data.
- **Multi-model support**: Swap between general-purpose and code-optimized models.
- **Internet-connected agents**: Perform live lookups using APIs (weather, Wikipedia, Wayback Machine, etc.).
- **User-friendly web interface**: Built on Open WebUI with persistent chat, file uploads, and agent triggering.
- **Ingestion from common formats**: Markdown, PDFs, Apple Notes, emails, and more.
- **Agent extensibility**: Easily add new tools like Brave Search, ArchiveBox, or Filesystem Scanners.

---

## ğŸ§â€ Core Components

- [**Kotaemon**](https://github.com/kota-ai/kotaemon) â€” Local LLM orchestration platform.
- [**Open WebUI**](https://github.com/open-webui/open-webui) â€” Friendly front-end interface.
- [**Qdrant Vector Database**](https://github.com/qdrant/qdrant) â€” Fast semantic search backend.
- [**WireGuard VPN (Optional)**](https://www.wireguard.com/) â€” For outbound agent privacy.

---

## ğŸ§  Supported Models

### ğŸ”® General-Purpose Chat
- `llama-3-8b-lexi-uncensored.Q4_K_M.gguf`
- `llama-3-8b-lexi-uncensored.Q2_K.gguf`

### ğŸ’» Code Generation
- `deepseek-coder-1.3b-instruct.Q4_K_M.gguf`
- `deepseek-coder-6.7b-instruct.Q4_K_M.gguf`

All models are run with `llama.cpp` (GGUF format) and swappable in the UI.

---

## ğŸ” Embedding Backend

- `nomic-embed-text-v1.5` â€” Fast, high-quality local embedding model from Nomic AI.

---

## ğŸ“† Ingestion Pipelines (Local Data)

| Type | Description |
|------|-------------|
| ğŸ“‚ Filesystem Scanner | Crawl specified directories for `.pdf`, `.txt`, `.md`, `.docx`, etc. |
| ğŸ“ Apple Notes | Ingest `.txt` or `.html` exports from Apple Notes |
| ğŸ““ Obsidian Vault | Use `.md` files from your knowledge base |
| ğŸ“§ Email Agent | Parse `.eml`, `.mbox`, or `.txt` email exports |
| ğŸ“… Calendar Agent | Ingest `.ics` or `.csv` calendar data |
| ğŸ’³ Financial Data | Load `.csv` or `.pdf` statements for spending analysis |
| ğŸ—ƒï¸ ArchiveBox | Search your self-hosted web archive (HTML, PDFs, screenshots, full-text) |

---

## ğŸŒ Internet-Connected Agents

| Agent | Purpose |
|-------|---------|
| ğŸ›™ Brave Search | Privacy-respecting search API |
| ğŸŒ Wikipedia | Fetch structured Wikipedia content |
| âŒ› Wayback Machine | Look up old/deleted URLs |
| ğŸ—“ï¸ Calendar | Query local calendar data |
| ğŸ’¸ Finance | Parse and analyze spending data |
| ğŸ“¨ Email | Search messages, invoices, etc. |
| â›… Weather | Live weather via OpenWeather API |
| ğŸ“Š Stock Market | Market data from Yahoo or Alpha Vantage |
| ğŸ“ Google Search | Fallback to general search |
| ğŸ›ï¸ Google Maps | Places, directions, business info |
| ğŸŒ OpenStreetMap | Open geographic data |

---

## ğŸ”’ Privacy & Networking

- All model inference and embedding occurs **100% locally**.
- All document indexing is done on your machine or LAN.
- Internet access is **only used by agents**, and can be disabled.
- Optional VPN routing supported via **WireGuard** using **Gluetun** container.

You can enable container-level VPN by uncommenting the `gluetun` section in `docker-compose.yml`.

---

## ğŸ“Œ Use Case Examples

| Prompt | Example Agents Triggered |
|--------|---------------------------|
| â€œSearch for news on AI regulation in the EU.â€ | Brave Search, Google Search |
| â€œWhatâ€™s the forecast for Seattle this weekend?â€ | Weather Agent |
| â€œWhatâ€™s on my calendar for Tuesday?â€ | Calendar Agent |
| â€œSummarize my Obsidian vault on stoicism.â€ | Obsidian Ingestor + RAG |
| â€œFind emails from Comcast with attachments.â€ | Email Agent |
| â€œWhat was AAPLâ€™s stock price last month?â€ | Stock Market Agent |
| â€œFind archived version of this broken link.â€ | Wayback Machine |
| â€œGive me restaurants near my hotel in Paris.â€ | Google Maps, OpenStreetMap |
| â€œTell me what I spent on subscriptions last quarter.â€ | Finance Agent |
| â€œSearch my ArchiveBox for past research on AI ethics.â€ | ArchiveBox Ingestor + RAG |

---

## ğŸ› ï¸ Hardware Requirements

| Resource | Minimum |
|----------|---------|
| CPU | Quad-core with AVX2 (or better) |
| RAM | 8 GB (16 GB+ recommended) |
| Storage | 100 GB SSD minimum |
| GPU | Optional (Metal/CUDA for faster inference) |

> âœ… Model and vector DB directories can be mounted over NFS or SMB if preferred.

---

## ğŸ“ Project Structure





```
repo-root/
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env
â”œâ”€â”€ settings.yaml
â”‚
â”œâ”€â”€ models/               # Pre-downloaded GGUF models
â”œâ”€â”€ qdrant_data/          # Persistent vector DB storage
â”œâ”€â”€ archivebox_data/
â”œâ”€â”€ email_exports/
â”œâ”€â”€ obsidian/
â”œâ”€â”€ notes_ingest/
â”œâ”€â”€ financial_data/
â”œâ”€â”€ calendar/
â”‚
â””â”€â”€ syncthing_data/       # Optional file sync
```


---

## ğŸ¥ Setup Instructions

Coming soon...

Includes:

- Mount instructions (for NAS-backed folders)
- `.env` config walkthrough
- VPN toggle instructions
- How to run and update containers
